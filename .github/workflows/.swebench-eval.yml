name: SWE-bench Pro Evaluation (Gemini)

on:
  workflow_dispatch:
    inputs:
      task_id:
        description: "Task ID to run"
        required: true
        default: "internetarchive__openlibrary-c4eebe6677acc4629cb541a98d5e91311444f5d4"

jobs:
  evaluate:
    runs-on: ubuntu-latest
    container:
      image: manojva/openlibrary-python312:latest
      options: --user root

    env:
      TASK_ID: ${{ github.event.inputs.task_id }}
      PYTHONPATH: /testbed
      GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
      GEMINI_MODEL: gemini-1.5-pro

    steps:
      # ----------------------------
      # Checkout harness repo
      # ----------------------------
      - name: Checkout harness repo
        uses: actions/checkout@v4

      # ----------------------------
      # Clone OpenLibrary at commit
      # ----------------------------
      - name: Setup OpenLibrary repository
        shell: bash
        run: |
          mkdir -p /testbed
          COMMIT_HASH=$(echo "$TASK_ID" | rev | cut -d'-' -f1 | rev)
          git clone https://github.com/internetarchive/openlibrary.git /testbed
          cd /testbed
          git checkout "$COMMIT_HASH"

      # ----------------------------
      # Prepare artifacts directory
      # ----------------------------
      - name: Prepare artifacts directory
        run: mkdir -p /workspace/artifacts

      # ----------------------------
      # Configure Git for CI
      # ----------------------------
      - name: Configure Git for CI
        shell: bash
        run: |
          git config --global user.email "ci@localhost"
          git config --global user.name "CI Bot"

      # ----------------------------
      # System dependencies
      # ----------------------------
      - name: Install system dependencies
        shell: bash
        run: |
          apt-get update
          apt-get install -y build-essential libpq-dev

      # ----------------------------
      # Python dependencies
      # ----------------------------
      - name: Install Python dependencies
        shell: bash
        run: |
          cd /testbed
          python -m pip install --upgrade pip
          pip install \
            pytest \
            web.py \
            simplejson \
            babel \
            python-dateutil \
            requests \
            psycopg2-binary \
            Cython \
            setuptools \
            wheel \
            google-generativeai \
            google-genai \
            python-memcached

      # ----------------------------
      # Install infogami
      # ----------------------------
      - name: Install infogami
        shell: bash
        run: |
          cd /opt
          if [ ! -d infogami ]; then
            git clone https://github.com/internetarchive/infogami.git
          fi
          pip install -e infogami

      # ----------------------------
      # Copy Gemini agent script to /testbed
      # ----------------------------
      - name: Copy Gemini agent script
        shell: bash
        run: |
          cp -r $GITHUB_WORKSPACE/scripts /testbed/

      # ----------------------------
      # Pre-validation: run tests and log failures
      # ----------------------------
      - name: Pre-validation checks
        shell: bash
        run: |
          cd /testbed
          echo "=== Pre-validation test results ===" > /workspace/artifacts/pre_verification.log
          # Run pytest and capture failures
          pytest openlibrary/tests --maxfail=0 --disable-warnings --tb=short --color=no \
            | tee -a /workspace/artifacts/pre_verification.log
          echo "=== End of Pre-validation ===" >> /workspace/artifacts/pre_verification.log

      # ----------------------------
      # Baseline commit to track changes
      # ----------------------------
      - name: Baseline commit
        shell: bash
        run: |
          cd /testbed
          git add -A
          git commit -m "pre-agent baseline" || true

      # ----------------------------
      # Run Gemini agent
      # ----------------------------
      - name: Run Gemini agent
        shell: bash
        run: |
          cd /testbed
          python scripts/run_agent.py \
            --task-id "$TASK_ID" \
            --repo-path /testbed \
            --log-path /workspace/artifacts/agent.log \
            --prompt-log /workspace/artifacts/prompts.md \
            --pre-log /workspace/artifacts/pre_verification.log \
            --post-log /workspace/artifacts/post_verification.log \
            --results /workspace/artifacts/results.json \
            --model "$GEMINI_MODEL"

      # ----------------------------
      # Post-validation: rerun tests after agent changes
      # ----------------------------
      - name: Post-validation checks
        shell: bash
        run: |
          cd /testbed
          echo "=== Post-validation test results ===" > /workspace/artifacts/post_verification.log
          pytest openlibrary/tests --maxfail=0 --disable-warnings --tb=short --color=no \
            | tee -a /workspace/artifacts/post_verification.log
          echo "=== End of Post-validation ===" >> /workspace/artifacts/post_verification.log

      # ----------------------------
      # Capture patch of changes made by agent
      # ----------------------------
      - name: Capture code changes
        if: always()
        shell: bash
        run: |
          cd /testbed
          git add -A
          git diff HEAD~1 HEAD > /workspace/artifacts/changes.patch || true

      # ----------------------------
      # Upload all artifacts
      # ----------------------------
      - name: Upload evaluation artifacts
        uses: actions/upload-artifact@v4
        with:
          name: swebench-eval-artifacts
          path: /workspace/artifacts
