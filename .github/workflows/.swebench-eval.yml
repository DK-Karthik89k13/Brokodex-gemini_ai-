name: SWE-bench Pro Evaluation (Gemini)

on:
  workflow_dispatch:
    inputs:
      task_id:
        description: "Task ID to run"
        required: true
        default: "internetarchive__openlibrary-c4eebe6677acc4629cb541a98d5e91311444f5d4"

jobs:
  evaluate:
    runs-on: ubuntu-latest
    container:
      image: manojva/openlibrary-python312:latest
      options: --user root

    env:
      TASK_ID: ${{ github.event.inputs.task_id }}
      PYTHONPATH: /testbed/openlibrary
      GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
      GEMINI_MODEL: gemini-1.5-pro

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Prepare directories
        run: |
          mkdir -p /workspace/artifacts
          mkdir -p /testbed

      - name: Setup OpenLibrary repository
        shell: bash
        run: |
          set -e
          COMMIT_HASH=$(echo "$TASK_ID" | rev | cut -d'-' -f1 | rev)
          git clone https://github.com/internetarchive/openlibrary.git /testbed || true
          cd /testbed
          git fetch --all
          git checkout "$COMMIT_HASH"

      - name: Install Python dependencies
        shell: bash
        run: |
          cd /testbed/openlibrary
          python -m pip install --upgrade pip
          pip install Cython wheel pytest web.py google-genai google-generativeai
        env:
          PYTHONPATH: /testbed/openlibrary

      - name: Pre-verification test (expected to fail)
        shell: bash
        run: |
          set +e
          cd /testbed
          python -m pytest \
            openlibrary/tests/core/test_imports.py::TestImportItem::test_find_staged_or_pending \
            -xvs | tee /workspace/artifacts/pre_verification.log
          echo $? > /workspace/artifacts/pre_verification.exit
          exit 0

      - name: Assert pre-verification failed
        shell: bash
        run: |
          [ "$(cat /workspace/artifacts/pre_verification.exit)" -ne 0 ] || exit 1

      - name: Run Gemini agent
        shell: bash
        run: |
          python scripts/run_agent.py \
            --task-id "$TASK_ID" \
            --repo-path /testbed \
            --log-path /workspace/artifacts/agent.log \
            --prompt-log /workspace/artifacts/prompts.md \
            --pre-log /workspace/artifacts/pre_verification.log \
            --post-log /workspace/artifacts/post_verification.log \
            --results /workspace/artifacts/results.json \
            --model "$GEMINI_MODEL"
        env:
          PYTHONPATH: /testbed/openlibrary

      - name: Capture code changes
        if: always()
        shell: bash
        run: |
          cd /testbed
          git diff > /workspace/artifacts/changes.patch || true

      - name: Post-verification test
        shell: bash
        run: |
          cd /testbed
          python -m pytest \
            openlibrary/tests/core/test_imports.py::TestImportItem::test_find_staged_or_pending \
            -xvs | tee /workspace/artifacts/post_verification.log

      - name: Upload evaluation artifacts
        uses: actions/upload-artifact@v4
        with:
          name: swebench-eval-artifacts
          path: /workspace/artifacts
