name: SWE-bench Pro Evaluation (Gemini)

on:
  workflow_dispatch:
    inputs:
      task_id:
        description: "Task ID to run"
        required: true
        default: "internetarchive__openlibrary-c4eebe6677acc4629cb541a98d5e91311444f5d4"

jobs:
  evaluate:
    runs-on: ubuntu-latest
    container:
      image: manojva/openlibrary-python312:latest
      options: --user root

    env:
      TASK_ID: ${{ github.event.inputs.task_id }}
      PYTHONPATH: /testbed
      GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
      GEMINI_MODEL: gemini-1.5-pro

    steps:
      # ----------------------------
      # Checkout repo
      # ----------------------------
      - name: Checkout harness repo
        uses: actions/checkout@v4

      # ----------------------------
      # Prepare directories
      # ----------------------------
      - name: Prepare directories
        run: |
          mkdir -p /workspace/artifacts
          mkdir -p /testbed

      # ----------------------------
      # Clone OpenLibrary at commit
      # ----------------------------
      - name: Setup OpenLibrary repository
        shell: bash
        run: |
          set -e
          COMMIT_HASH=$(echo "$TASK_ID" | rev | cut -d'-' -f1 | rev)
          git clone https://github.com/internetarchive/openlibrary.git /testbed
          cd /testbed
          git checkout "$COMMIT_HASH"

      # ----------------------------
      # Configure Git identity for commits
      # ----------------------------
      - name: Configure Git identity
        run: |
          git config --global user.email "agent@example.com"
          git config --global user.name "SWE Agent"

      # ----------------------------
      # System dependencies
      # ----------------------------
      - name: Install system dependencies
        run: |
          apt-get update
          apt-get install -y build-essential libpq-dev python3-venv git

      # ----------------------------
      # Setup virtual environment & Python deps
      # ----------------------------
      - name: Setup Python venv
        run: |
          python -m venv /testbed/.venv
          source /testbed/.venv/bin/activate
          python -m pip install --upgrade pip
          pip install \
            pytest pytest-asyncio web.py simplejson babel python-dateutil requests \
            psycopg2-binary Cython setuptools wheel google-generativeai google-genai \
            python-memcached validate_email lxml eventer pymemcache aiofiles luqum

      # ----------------------------
      # Install infogami (idempotent)
      # ----------------------------
      - name: Install infogami
        run: |
          source /testbed/.venv/bin/activate
          cd /opt
          if [ ! -d infogami ]; then
            git clone https://github.com/internetarchive/infogami.git
          fi
          pip install -e infogami

      # ----------------------------
      # Pre-validation: test environment
      # ----------------------------
      - name: Pre-validation
        shell: bash
        run: |
          source /testbed/.venv/bin/activate
          cd /testbed
          pytest --maxfail=5 --disable-warnings --tb=short | tee /workspace/artifacts/pre_validation.log

      # ----------------------------
      # Run Gemini agent to evaluate & patch
      # ----------------------------
      - name: Run Gemini agent
        shell: bash
        run: |
          source /testbed/.venv/bin/activate
          python /testbed/scripts/run_agent.py \
            --task-id "$TASK_ID" \
            --repo-path /testbed \
            --log-path /workspace/artifacts/agent.log \
            --prompt-log /workspace/artifacts/prompts.md \
            --pre-log /workspace/artifacts/pre_validation.log \
            --post-log /workspace/artifacts/post_validation.log \
            --results /workspace/artifacts/results.json \
            --model "$GEMINI_MODEL"

      # ----------------------------
      # Post-validation after agent changes
      # ----------------------------
      - name: Post-validation
        shell: bash
        run: |
          source /testbed/.venv/bin/activate
          cd /testbed
          pytest --maxfail=5 --disable-warnings --tb=short | tee /workspace/artifacts/post_validation.log

      # ----------------------------
      # Capture code changes
      # ----------------------------
      - name: Capture code changes
        if: always()
        run: |
          cd /testbed
          git diff > /workspace/artifacts/changes.patch || true

      # ----------------------------
      # Upload artifacts
      # ----------------------------
      - name: Upload evaluation artifacts
        uses: actions/upload-artifact@v4
        with:
          name: swebench-eval-artifacts
          path: /workspace/artifacts
