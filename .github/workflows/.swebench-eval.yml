name: SWE-bench Pro Evaluation (Gemini)

on:
  workflow_dispatch:
    inputs:
      task_id:
        description: 'Task ID to run'
        required: true
        default: 'internetarchive__openlibrary-c4eebe6677acc4629cb541a98d5e91311444f5d4'

jobs:
  evaluate:
    runs-on: ubuntu-latest
    container:
      image: manojva/openlibrary-python312:latest
      options: --user root

    env:
      TASK_ID: ${{ github.event.inputs.task_id }}

    steps:
      - name: Checkout evaluation repository
        uses: actions/checkout@v4

      - name: Prepare directories
        run: |
          mkdir -p /workspace/artifacts
          mkdir -p /testbed
          
      - name: Setup OpenLibrary repository
        shell: bash
        env:
          REPO_NAME: "internetarchive/openlibrary"
          BASE_COMMIT: ${{ github.event.inputs.base_commit || 'master' }} # Or a hardcoded SHA
        run: |
          # The file must exist now!
          chmod +x scripts/setup_repository.sh
          ./scripts/setup_repository.sh | tee /workspace/artifacts/setup.log

     
      - name: Pre-verification test (expected to fail)
        shell: bash
        run: |
          set +e
          cd /testbed
          python -m pytest \
            openlibrary/tests/core/test_imports.py::TestImportItem::test_find_staged_or_pending \
            -xvs | tee /workspace/artifacts/pre_verification.log
          echo $? > /workspace/artifacts/pre_verification.exit
          exit 0

      - name: Assert pre-verification failed
        shell: bash
        run: |
          EXIT_CODE=$(cat /workspace/artifacts/pre_verification.exit)
          if [ "$EXIT_CODE" -ne 0 ]; then
            echo "✅ Pre-verification failed as expected"
          else
            echo "❌ Pre-verification unexpectedly passed"
            exit 1
          fi

      # --- UPDATED: Install Google SDK ---
      - name: Install Google Generative AI SDK
        shell: bash
        run: |
          python -m pip install --upgrade pip
          pip install google-generativeai

      # --- UPDATED: Run Gemini agent ---
      - name: Run Gemini agent
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          python scripts/run_agent.py \
            --task-id "$TASK_ID" \
            --repo-path /testbed \
            --log-path /workspace/artifacts/agent.log \
            --prompt-log /workspace/artifacts/prompts.md

      - name: Capture code changes
        shell: bash
        run: |
          cd /testbed
          git diff > /workspace/artifacts/changes.patch

      - name: Ensure AI produced a patch
        shell: bash
        run: |
          if [ ! -s /workspace/artifacts/changes.patch ]; then
            echo "❌ AI produced no code changes"; exit 1
          else
            echo "✅ AI produced code changes"; fi

      - name: Post-verification test (expected to pass)
        shell: bash
        run: |
          cd /testbed
          python -m pytest \
            openlibrary/tests/core/test_imports.py::TestImportItem::test_find_staged_or_pending \
            -xvs | tee /workspace/artifacts/post_verification.log

      - name: Assert post-verification passed
        shell: bash
        run: |
          if grep -q "FAILED" /workspace/artifacts/post_verification.log; then
            echo "❌ Post-verification failed"; exit 1
          else
            echo "✅ Post-verification passed"; fi

      - name: Extract evaluation metrics
        run: |
          python scripts/extract_metrics.py \
            --agent-log /workspace/artifacts/agent.log \
            --output /workspace/artifacts/result.json

      - name: Upload evaluation artifacts
        uses: actions/upload-artifact@v4
        with:
          name: swebench-eval-artifacts
          path: /workspace/artifacts
